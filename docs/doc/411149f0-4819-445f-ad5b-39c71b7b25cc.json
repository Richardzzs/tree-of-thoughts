{
    "summary": "This code initializes an OpenAI language model, generating text using the Chat API. It supports ReAct prompting, generates solutions, learns from errors, and evaluates states with an API.",
    "details": [
        {
            "comment": "This code is initializing a logging configuration and defining the OpenAILanguageModel class, which extends AbstractLanguageModel. The OpenAILanguageModel is an OpenAI language model with options for strategy, evaluation_strategy, api_base, api_model, enable_ReAct_prompting, and more. It allows for generating and evaluating thoughts using OpenAI API.",
            "location": "\"/media/root/Prima/works/tree-of-thoughts/docs/src/tree_of_thoughts/openai_models.py\":0-33",
            "content": "import logging\nfrom tree_of_thoughts.base import AbstractLanguageModel\nfrom swarms.models import OpenAIChat\n# Logging\nlogging.basicConfig(\n    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(__name__)\nclass OpenAILanguageModel(AbstractLanguageModel):\n    \"\"\"\n    OpenAI Language Model\n    Args:\n        api_key (str): OpenAI API key\n        strategy (str): Strategy for generating thoughts. Choose from 'cot' (Chain of Thoughts) or 'gpt' (GPT-3)\n        evaluation_strategy (str): Strategy for evaluating thoughts. Choose from 'value' or 'vote'\n        api_base (str): Base path for OpenAI API\n        api_model (str): Model name for OpenAI API\n        enable_ReAct_prompting (bool): Enable ReAct prompting\n    Examples:\n    >>> from tree_of_thoughts.models.openai_models import OpenAILanguageModel\n    >>> model = OpenAILanguageModel(api_key=api_key)\n    >>> model.generate_thoughts(state, k)\n    >>> model.evaluate_states(states, initial_prompt)\n    \"\"\"\n    def __init__("
        },
        {
            "comment": "Class initializes OpenAI Chat API for generating text. It allows ReAct prompting, which requires a specific format of observations and thoughts. Uses generate_text() function to produce text based on the given prompt.",
            "location": "\"/media/root/Prima/works/tree-of-thoughts/docs/src/tree_of_thoughts/openai_models.py\":34-63",
            "content": "        self,\n        api_key,\n        strategy=\"cot\",\n        evaluation_strategy=\"value\",\n        enable_ReAct_prompting=True,\n        *args,\n        **kwargs,\n    ):\n        self.api_key = api_key\n        self.use_chat_api = True\n        self.enable_ReAct_prompting = enable_ReAct_prompting\n        self.strategy = strategy\n        self.evaluation_strategy = evaluation_strategy\n        # reference : https://www.promptingguide.ai/techniques/react\n        self.ReAct_prompt = \"\"\n        if enable_ReAct_prompting:\n            self.ReAct_prompt = (\n                \"Write down your observations in format 'Observation:xxxx',\"\n                \" then write down your thoughts in format 'Thoughts:xxxx'.\"\n            )\n        self.model = OpenAIChat(openai_api_key=api_key, *args, **kwargs)\n    def generate_text(self, prompt: str, k: int = 3):\n        \"\"\"Generate text from prompt using OpenAI API\"\"\"\n        if self.use_chat_api:\n            thoughts = []\n            for _ in range(k):\n                response = self.model(prompt)"
        },
        {
            "comment": "The code defines a class with two methods: `generate_thoughts` and `openai_models`. The `generate_thoughts` method takes a state, number of thoughts to generate, initial prompt, and list of rejected solutions as input. It converts the state into a string and passes it along with other parameters to the `openai_models` method which generates a list of thoughts using OpenAI API. The thoughts are then returned by the `generate_thoughts` method.",
            "location": "\"/media/root/Prima/works/tree-of-thoughts/docs/src/tree_of_thoughts/openai_models.py\":64-91",
            "content": "                thoughts += [response]\n                # print(f'thoughts: {thoughts}')\n            return thoughts\n    def generate_thoughts(\n        self, state, k, initial_prompt, rejected_solutions=None\n    ):\n        \"\"\"\n        Generate thoughts from state using OpenAI API\n        Args:\n            state (str or list): State of reasoning\n            k (int): Number of thoughts to generate\n            initial_prompt (str): Initial prompt\n            rejected_solutions (list): List of rejected solutions\n        Returns:\n            list: List of thoughts\n        \"\"\"\n        if type(state) == str:\n            state_text = state\n        else:\n            state_text = \"\\n\".join(state)\n        print(\"New state generating thought:\", state, \"\\n\\n\")\n        prompt = f\"\"\"You're an TreeofThoughts, an superintelligent AI model devoted to helping Humans by any means necessary. You're purpose is to generate a series of solutions to comply with the user's instructions, you must generate solutions on the basis of de"
        },
        {
            "comment": "This code is generating a prompt for an AI model to find the best solution, taking into account rejected solutions and learning from them. The function generates_solution is used to generate a solution given a prompt, state, and optionally a list of rejected solutions. It creates a formatted prompt including the initial prompt, the current state, and either all rejected solutions or none. Then it calls another function, generate_text, with this prompt and some variable k to generate thoughts based on this prompt. Finally, it returns these thoughts as the generated solution.",
            "location": "\"/media/root/Prima/works/tree-of-thoughts/docs/src/tree_of_thoughts/openai_models.py\":91-109",
            "content": "termining the most reliable solution in the shortest amount of time, while taking rejected solutions into account and learning from them. \n        Considering the reasoning provided:\\n\\n\n        ###'{state_text}'\\n\\n###\n        Devise the best possible solution for the task: {initial_prompt}, Here are evaluated solutions that were rejected: \n        ###{rejected_solutions}###, \n        complete the {initial_prompt} without making the same mistakes you did with the evaluated rejected solutions. Be simple. Be direct. Provide intuitive solutions as soon as you think of them.\"\"\"\n        prompt += self.ReAct_prompt\n        thoughts = self.generate_text(prompt, k)\n        return thoughts\n    def generate_solution(self, initial_prompt, state, rejected_solutions=None):\n        try:\n            if isinstance(state, list):\n                state_text = \"\\n\".join(state)\n            else:\n                state_text = state\n            prompt = f\"\"\"You're an TreeofThoughts, an superintelligent AI model devoted to "
        },
        {
            "comment": "This code aims to generate a solution for a task based on user instructions, learning from rejected solutions and avoiding the same mistakes. It generates one textual answer with simplicity and directness. If an exception occurs, it logs the error.",
            "location": "\"/media/root/Prima/works/tree-of-thoughts/docs/src/tree_of_thoughts/openai_models.py\":109-121",
            "content": "helping Humans by any means necessary. You're purpose is to generate a series of solutions to comply with the user's instructions, you must generate solutions on the basis of determining the most reliable solution in the shortest amount of time, while taking rejected solutions into account and learning from them. \n            Considering the reasoning provided:\\n\\n\n            ###'{state_text}'\\n\\n###\n            Devise the best possible solution for the task: {initial_prompt}, Here are evaluated solutions that were rejected: \n            ###{rejected_solutions}###, \n            complete the {initial_prompt} without making the same mistakes you did with the evaluated rejected solutions. Be simple. Be direct. Provide intuitive solutions as soon as you think of them.\"\"\"\n            answer = self.generate_text(prompt, 1)\n            print(f\"Answerrrrrr {answer}\")\n            # print(thoughts)\n            # print(f\"General Solution : {answer}\")\n            return answer\n        except Exception as e:\n            logger.error(f\"Error in generate_solutions: {e}\")"
        },
        {
            "comment": "The code defines a function `evaluate_states` that takes in a list of states and an initial prompt. It iterates over each state, checks its type, and prints details about the state. If the evaluation strategy is set to \"value\", it calculates the value of each state by pessimistically valuing the context of past solutions and the latest generated solution as a float between 0 and 1.",
            "location": "\"/media/root/Prima/works/tree-of-thoughts/docs/src/tree_of_thoughts/openai_models.py\":122-145",
            "content": "            return None\n    def evaluate_states(self, states, initial_prompt):\n        if not states:\n            return {}\n        if self.evaluation_strategy == \"value\":\n            state_values = {}\n            for state in states:\n                if type(state) == str:\n                    state_text = state\n                else:\n                    state_text = \"\\n\".join(state)\n                print(\n                    \"We receive a state of type\",\n                    type(state),\n                    \"For state: \",\n                    state,\n                    \"\\n\\n\",\n                )\n                prompt = f\"\"\" To achieve the following goal: '{initial_prompt}', pessimistically value the context of the past solutions and more importantly the latest generated solution you had AS A FLOAT BETWEEN 0 AND 1\\n\n                    Past solutions:\\n\\n\n                    {state_text}\\n       \n                    If the solutions is not directly concretely making fast progress in achieving the goal, give it a lower score."
        },
        {
            "comment": "The code evaluates thought values using an open-source API call, converts the response to a float value between 0 and 1, and stores the results in a dictionary. It handles conversion errors by assigning a default value of 0 for invalid input. The evaluation strategy can be either \"float\" or \"vote\", with the latter requiring a user to choose the best state from multiple options.",
            "location": "\"/media/root/Prima/works/tree-of-thoughts/docs/src/tree_of_thoughts/openai_models.py\":146-167",
            "content": "                    Evaluate all solutions AS A FLOAT BETWEEN 0 and 1:\\n,  DO NOT RETURN ANYTHING ELSE\n                \"\"\"\n                response = self.openai_api_call_handler(prompt, 10, 1)\n                try:\n                    value_text = self.openai_choice2text_handler(\n                        response.choices[0]\n                    )\n                    # print(f'state: {value_text}')\n                    value = float(value_text)\n                    print(f\"Evaluated Thought Value: {value}\")\n                except ValueError:\n                    value = 0  # Assign a default value if the conversion fails\n                state_values[state] = value\n            return state_values\n        elif self.evaluation_strategy == \"vote\":\n            states_text = \"\\n\".join([\" \".join(state) for state in states])\n            prompt = (\n                \"Given the following states of reasoning, vote for the best\"\n                \" state utilizing an scalar value\"\n                f\" 1-10:\\n{states_text}\\n\\nVote, on the probability of this\""
        },
        {
            "comment": "Code makes an OpenAI API call to generate a response based on the provided prompt. It then selects the best state from the generated text, assigns a value of 1 if it matches the best state and 0 otherwise for each state in the input states. If an invalid evaluation strategy is provided, it raises a ValueError.",
            "location": "\"/media/root/Prima/works/tree-of-thoughts/docs/src/tree_of_thoughts/openai_models.py\":168-185",
            "content": "                f\" state of reasoning achieveing {initial_prompt} and become\"\n                \" very pessimistic very NOTHING ELSE\"\n            )\n            response = self.openai_api_call_handler(prompt, 50, 1)\n            print(f\"state response: {response}\")\n            best_state_text = self.openai_choice2text_handler(\n                response.choices[0]\n            )\n            print(f\"Best state text: {best_state_text}\")\n            best_state = tuple(best_state_text.split())\n            print(f\"best_state: {best_state}\")\n            return {state: 1 if state == best_state else 0 for state in states}\n        else:\n            raise ValueError(\n                \"Invalid evaluation strategy. Choose 'value' or 'vote'.\"\n            )"
        }
    ]
}